{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9d3d2b84f4f2473cb84a9d65b1c8ad2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ead92ca8d4d4f53bc8df7abad670902",
              "IPY_MODEL_0842c1b31c424813b2f8744d3547e625",
              "IPY_MODEL_47e3ba3a75c54ff6931c0d3ed4ad8073"
            ],
            "layout": "IPY_MODEL_a35579e27d4a4f59a8a9abd4ed3d4037"
          }
        },
        "0ead92ca8d4d4f53bc8df7abad670902": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b3430eb4a494e41993a146dcd869c99",
            "placeholder": "​",
            "style": "IPY_MODEL_a9d3477654704444bc008d8363344b71",
            "value": "Map: 100%"
          }
        },
        "0842c1b31c424813b2f8744d3547e625": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdc221672b2f4297b0c92c84f3fcc717",
            "max": 1045,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a8716362f3d54900ae044927e766aa43",
            "value": 1045
          }
        },
        "47e3ba3a75c54ff6931c0d3ed4ad8073": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e8022507a20450b9db9b11d253d232e",
            "placeholder": "​",
            "style": "IPY_MODEL_afb71342a6264a4796c2500a9f36f049",
            "value": " 1045/1045 [00:04&lt;00:00, 96.00 examples/s]"
          }
        },
        "a35579e27d4a4f59a8a9abd4ed3d4037": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b3430eb4a494e41993a146dcd869c99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9d3477654704444bc008d8363344b71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cdc221672b2f4297b0c92c84f3fcc717": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8716362f3d54900ae044927e766aa43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e8022507a20450b9db9b11d253d232e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afb71342a6264a4796c2500a9f36f049": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f330453f9cce4ca9b4968b0ce2984e1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b712b87cf37437c91de18c98f5049f2",
              "IPY_MODEL_f8f184bced824e55a70785d434f85db6",
              "IPY_MODEL_4b2a4d3a3c44459398c4e34344bcd2cf"
            ],
            "layout": "IPY_MODEL_70baa1357c384966add10623c10cd843"
          }
        },
        "6b712b87cf37437c91de18c98f5049f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_295414888416408ea6a3785ae1498130",
            "placeholder": "​",
            "style": "IPY_MODEL_ad8e0e5f575848798d7fc63dde766165",
            "value": "Map: 100%"
          }
        },
        "f8f184bced824e55a70785d434f85db6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79665ee45c764a7ea93f82213ac16bf2",
            "max": 55,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a9ce48a2e1fa48bba29d5285b1277254",
            "value": 55
          }
        },
        "4b2a4d3a3c44459398c4e34344bcd2cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20f47cf323434649ba07566d0a9b5f06",
            "placeholder": "​",
            "style": "IPY_MODEL_106b09c359bc4d26b59f5e03846c1884",
            "value": " 55/55 [00:00&lt;00:00, 137.64 examples/s]"
          }
        },
        "70baa1357c384966add10623c10cd843": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "295414888416408ea6a3785ae1498130": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad8e0e5f575848798d7fc63dde766165": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79665ee45c764a7ea93f82213ac16bf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9ce48a2e1fa48bba29d5285b1277254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "20f47cf323434649ba07566d0a9b5f06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "106b09c359bc4d26b59f5e03846c1884": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "033ee0bf7c1f454bb0f496491bc51799": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b8d9acf3ff4748498cd4c2ca62dc481c",
              "IPY_MODEL_d8d3b87700464d25abb31b4c24f9611c",
              "IPY_MODEL_dd685c6f7a844f269194e7571ed304c4"
            ],
            "layout": "IPY_MODEL_69bd9329486049d9bc87ec9ce0fad6ab"
          }
        },
        "b8d9acf3ff4748498cd4c2ca62dc481c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61535f7737444153b24e771bc8da3100",
            "placeholder": "​",
            "style": "IPY_MODEL_f7565bae7cdb48e4aa339bc757c8b9e3",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "d8d3b87700464d25abb31b4c24f9611c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a6b3e97464a4810841be9a8cbd8e3eb",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a37c3ee079d41a6ae6b2900ae5f172f",
            "value": 2
          }
        },
        "dd685c6f7a844f269194e7571ed304c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cffb8a3c421a4fe2ba71e16389e317d5",
            "placeholder": "​",
            "style": "IPY_MODEL_7f7bce0f6f00408ab74b39ad6072a1eb",
            "value": " 2/2 [01:00&lt;00:00, 28.95s/it]"
          }
        },
        "69bd9329486049d9bc87ec9ce0fad6ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61535f7737444153b24e771bc8da3100": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7565bae7cdb48e4aa339bc757c8b9e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a6b3e97464a4810841be9a8cbd8e3eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a37c3ee079d41a6ae6b2900ae5f172f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cffb8a3c421a4fe2ba71e16389e317d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f7bce0f6f00408ab74b39ad6072a1eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8625fb2bdda946a78e98fb10becb4d2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a8c7d270c9574510a4ffe66785ed5d80",
              "IPY_MODEL_faea42d066e54ce3b20c999807cb611d",
              "IPY_MODEL_e7f6fa782915452ab72d63dc0b42d26c"
            ],
            "layout": "IPY_MODEL_56d16621268649bd904bfd017d68f0c3"
          }
        },
        "a8c7d270c9574510a4ffe66785ed5d80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b32a681601b64077a245db56787e26b7",
            "placeholder": "​",
            "style": "IPY_MODEL_53f93845442f4519b526a293157321a0",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "faea42d066e54ce3b20c999807cb611d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9635256c50f146d982a902c22e8f3d6a",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_650b690793154a8ba4833b2d665e4935",
            "value": 2
          }
        },
        "e7f6fa782915452ab72d63dc0b42d26c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6d04f173bac4450b43ae7e321c9d040",
            "placeholder": "​",
            "style": "IPY_MODEL_ef5999377214420f936f97ff1715bee9",
            "value": " 2/2 [01:15&lt;00:00, 35.78s/it]"
          }
        },
        "56d16621268649bd904bfd017d68f0c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b32a681601b64077a245db56787e26b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53f93845442f4519b526a293157321a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9635256c50f146d982a902c22e8f3d6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "650b690793154a8ba4833b2d665e4935": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a6d04f173bac4450b43ae7e321c9d040": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef5999377214420f936f97ff1715bee9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import os, glob, shutil, json, random\n",
        "BASE_DIR     = \"/content/drive/MyDrive/nl2lp_project\"\n",
        "DATASET_DIR  = f\"{BASE_DIR}/datasets\"\n",
        "MERGED_DIR   = f\"{BASE_DIR}/merged\"\n",
        "CKPT_DIR     = f\"{BASE_DIR}/checkpoints\"\n",
        "OUT_DIR      = f\"{BASE_DIR}/nl2lp-phi3-qlora\"   # LoRA adapter will be saved here\n",
        "\n",
        "os.makedirs(DATASET_DIR, exist_ok=True)\n",
        "os.makedirs(MERGED_DIR,  exist_ok=True)\n",
        "os.makedirs(CKPT_DIR,    exist_ok=True)\n",
        "\n",
        "# expected filenames in Drive\n",
        "NL4_TRAIN = f\"{DATASET_DIR}/train.jsonl\"\n",
        "NL4_VAL   = f\"{DATASET_DIR}/val.jsonl\"\n",
        "NL4_NORM  = f\"{DATASET_DIR}/nl4opt_normalized.jsonl\"  # we will (re)build this\n",
        "TSP_OUT   = f\"{DATASET_DIR}/tsp_lp_dataset.jsonl\"     # we will build this\n",
        "\n",
        "print(\"DATASET_DIR:\", DATASET_DIR)\n",
        "print(\"MERGED_DIR:\", MERGED_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isCBCkxNTr2q",
        "outputId": "99617f9e-7254-4fa1-e2ca-e04a86efd058"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "DATASET_DIR: /content/drive/MyDrive/nl2lp_project/datasets\n",
            "MERGED_DIR: /content/drive/MyDrive/nl2lp_project/merged\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize duplicate file names in datasets\n",
        "candidates = glob.glob(f\"{DATASET_DIR}/*.jsonl\")\n",
        "for p in candidates:\n",
        "    base = os.path.basename(p)\n",
        "    if base.startswith(\"train (\") and base.endswith(\").jsonl\"):\n",
        "        shutil.copy(p, NL4_TRAIN); print(\"copied ->\", NL4_TRAIN)\n",
        "    if base.startswith(\"val (\") and base.endswith(\").jsonl\"):\n",
        "        shutil.copy(p, NL4_VAL);   print(\"copied ->\", NL4_VAL)\n",
        "\n",
        "# sanity check\n",
        "print(\"exists train:\", os.path.exists(NL4_TRAIN), NL4_TRAIN)\n",
        "print(\"exists val  :\", os.path.exists(NL4_VAL),   NL4_VAL)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2y1S9L9Turd",
        "outputId": "cff7a127-6498-42b0-964a-f8c849afc777"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "exists train: True /content/drive/MyDrive/nl2lp_project/datasets/train.jsonl\n",
            "exists val  : True /content/drive/MyDrive/nl2lp_project/datasets/val.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_jsonl(path):\n",
        "    rows = []\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for ln in f:\n",
        "            if ln.strip():\n",
        "                rows.append(json.loads(ln))\n",
        "    return rows\n",
        "\n",
        "def save_jsonl(rows, path):\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for r in rows:\n",
        "            f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "def norm_nl4(records):\n",
        "    out = []\n",
        "    for r in records:\n",
        "        instr = (r.get(\"instruction\") or\n",
        "                 r.get(\"input\") or\n",
        "                 r.get(\"prompt\") or\n",
        "                 r.get(\"problem_text\") or \"\").strip()\n",
        "        ans   = (r.get(\"output\") or\n",
        "                 r.get(\"answer\") or\n",
        "                 r.get(\"lp_string\") or \"\").strip()\n",
        "        if instr and ans:\n",
        "            out.append({\"instruction\": instr, \"input\": \"\", \"output\": ans, \"source\": \"nl4opt\"})\n",
        "    return out\n",
        "\n",
        "# must exist\n",
        "assert os.path.exists(NL4_TRAIN), \"train.jsonl missing\"\n",
        "assert os.path.exists(NL4_VAL),   \"val.jsonl missing\"\n",
        "\n",
        "tr_raw = load_jsonl(NL4_TRAIN)\n",
        "vl_raw = load_jsonl(NL4_VAL)\n",
        "tr = norm_nl4(tr_raw)\n",
        "vl = norm_nl4(vl_raw)\n",
        "\n",
        "save_jsonl(tr+vl, NL4_NORM)\n",
        "print(f\"✅ Normalized NL4Opt -> {NL4_NORM} (train {len(tr)}, val {len(vl)})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSB0DUs8Tzrt",
        "outputId": "f5893ee7-c858-4eda-da89-ec5e2ada1dd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Normalized NL4Opt -> /content/drive/MyDrive/nl2lp_project/datasets/nl4opt_normalized.jsonl (train 475, val 25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(42)\n",
        "\n",
        "def gen_complete_graph(cities, asymmetric=False, lo=5, hi=60):\n",
        "    C = {}\n",
        "    n = len(cities)\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            if i == j: continue\n",
        "            if asymmetric:\n",
        "                C[(cities[i], cities[j])] = random.randint(lo, hi)\n",
        "            else:\n",
        "                if j > i:\n",
        "                    d = random.randint(lo, hi)\n",
        "                    C[(cities[i], cities[j])] = d\n",
        "                    C[(cities[j], cities[i])] = d\n",
        "    return C\n",
        "\n",
        "def mtz_text_formulation(cities, C):\n",
        "    n = len(cities)\n",
        "    # objective\n",
        "    terms = [f\"{c}*x_{i}_{j}\" for (i,j), c in C.items()]\n",
        "    objective = \"Objective:\\n  Minimize Z = \" + \" + \".join(terms)\n",
        "\n",
        "    deg_out = [f\"  sum_{{j in {cities}}} x_{i}_{{j}} = 1\" for i in cities]\n",
        "    deg_in  = [f\"  sum_{{i in {cities}}} x_{{i}}_{j} = 1\" for j in cities]\n",
        "\n",
        "    mtz = [f\"  u_{cities[0]} = 1\", f\"  1 <= u_i <= {n} for all i in {cities}\"]\n",
        "    for i in cities:\n",
        "        for j in cities:\n",
        "            if i != j:\n",
        "                mtz.append(f\"  u_{i} - u_{j} + {n}*x_{i}_{j} <= {n}-1\")\n",
        "\n",
        "    binvars = [f\"  x_{i}_{j} in {{0,1}} for all i≠j in {cities}\"]\n",
        "    intvars = [f\"  u_i integer for all i in {cities}\"]\n",
        "\n",
        "    constraints = [\"Constraints:\"] + deg_out + deg_in + mtz + binvars + intvars\n",
        "    var_section = (\"Decision Variables:\\n\"\n",
        "                   \"  x_{i,j} = 1 if traveling directly from i to j; 0 otherwise\\n\"\n",
        "                   \"  u_i are MTZ order variables (1..n)\")\n",
        "\n",
        "    uniq_pairs, seen = [], set()\n",
        "    for (i,j), c in C.items():\n",
        "        if (j,i) in seen or i == j: continue\n",
        "        uniq_pairs.append(f\"{i}-{j}={c}\")\n",
        "        seen.add((i,j)); seen.add((j,i))\n",
        "    distances_nl = \", \".join(uniq_pairs)\n",
        "\n",
        "    nl_prompt = (f\"A salesman must visit all {n} cities exactly once and return. \"\n",
        "                 f\"Cities: {', '.join(cities)}. Distances: {distances_nl}. \"\n",
        "                 f\"Formulate an ILP using MTZ formulation.\")\n",
        "    lp_text = \"\\n\".join([objective, \"\", *constraints, \"\", var_section])\n",
        "    return nl_prompt, lp_text\n",
        "\n",
        "N_SAMPLES = 600\n",
        "with open(TSP_OUT, \"w\", encoding=\"utf-8\") as f:\n",
        "    for _ in range(N_SAMPLES):\n",
        "        n = random.randint(4, 8)\n",
        "        cities = [f\"C{i+1}\" for i in range(n)]\n",
        "        C = gen_complete_graph(cities, asymmetric=(random.random() < 0.3))\n",
        "        instr, out = mtz_text_formulation(cities, C)\n",
        "        f.write(json.dumps({\"instruction\": instr, \"input\": \"\", \"output\": out, \"source\": \"tsp\"}) + \"\\n\")\n",
        "print(f\"✅ Generated TSP -> {TSP_OUT} ({N_SAMPLES} rows)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXf5FAE25D_V",
        "outputId": "602228c3-54fb-492a-884d-1c75b3793a8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Generated TSP -> /content/drive/MyDrive/nl2lp_project/datasets/tsp_lp_dataset.jsonl (600 rows)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def read_jsonl(path):\n",
        "    return [json.loads(x) for x in open(path, \"r\", encoding=\"utf-8\").read().splitlines() if x.strip()]\n",
        "\n",
        "nl4_train = norm_nl4(read_jsonl(NL4_TRAIN))\n",
        "nl4_val   = norm_nl4(read_jsonl(NL4_VAL))\n",
        "tsp_all   = read_jsonl(TSP_OUT)\n",
        "\n",
        "tsp_train, tsp_val = train_test_split(tsp_all, test_size=0.05, random_state=42)\n",
        "\n",
        "merged_train = nl4_train + tsp_train\n",
        "merged_val   = nl4_val   + tsp_val\n",
        "random.shuffle(merged_train)\n",
        "random.shuffle(merged_val)\n",
        "\n",
        "MERGED_TRAIN = f\"{MERGED_DIR}/train.jsonl\"\n",
        "MERGED_VAL   = f\"{MERGED_DIR}/val.jsonl\"\n",
        "save_jsonl(merged_train, MERGED_TRAIN)\n",
        "save_jsonl(merged_val,   MERGED_VAL)\n",
        "\n",
        "print(\"✅ merged sizes:\", len(merged_train), \"(train),\", len(merged_val), \"(val)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDEctxnX5GdP",
        "outputId": "8794d50a-a58f-4664-8b01-1992a41085c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ merged sizes: 1045 (train), 55 (val)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "BASE_MODEL = \"microsoft/Phi-3-mini-4k-instruct\"   # 👈 switched model\n",
        "MAX_LEN    = 1024\n",
        "\n",
        "SYSTEM_PREFIX = (\n",
        "    \"You are an Operations Research expert. \"\n",
        "    \"Given a natural-language problem, respond ONLY with a clean LP/ILP formulation:\\n\"\n",
        "    \"Objective:\\nConstraints:\\nDecision Variables:\\n\"\n",
        ")\n",
        "\n",
        "def build_text(rec):\n",
        "    return f\"{SYSTEM_PREFIX}\\n\\nProblem: {rec['instruction']}\\nAnswer:\\n{rec['output']}\"\n",
        "\n",
        "tok = AutoTokenizer.from_pretrained(BASE_MODEL, use_fast=True)\n",
        "if tok.pad_token is None:\n",
        "    tok.pad_token = tok.eos_token\n",
        "\n",
        "def load_local_jsonl(path):\n",
        "    return Dataset.from_list([json.loads(l) for l in open(path, \"r\").read().splitlines() if l.strip()])\n",
        "\n",
        "train_ds = load_local_jsonl(MERGED_TRAIN)\n",
        "val_ds   = load_local_jsonl(MERGED_VAL)\n",
        "\n",
        "def map_format(ex):\n",
        "    text = build_text(ex)\n",
        "    enc = tok(text, max_length=MAX_LEN, truncation=True, padding=\"max_length\")\n",
        "    enc[\"labels\"] = enc[\"input_ids\"].copy()\n",
        "    return enc\n",
        "\n",
        "train_tok = train_ds.map(map_format, remove_columns=train_ds.column_names)\n",
        "val_tok   = val_ds.map(map_format,   remove_columns=val_ds.column_names)\n",
        "\n",
        "len(train_tok), len(val_tok)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209,
          "referenced_widgets": [
            "9d3d2b84f4f2473cb84a9d65b1c8ad2b",
            "0ead92ca8d4d4f53bc8df7abad670902",
            "0842c1b31c424813b2f8744d3547e625",
            "47e3ba3a75c54ff6931c0d3ed4ad8073",
            "a35579e27d4a4f59a8a9abd4ed3d4037",
            "4b3430eb4a494e41993a146dcd869c99",
            "a9d3477654704444bc008d8363344b71",
            "cdc221672b2f4297b0c92c84f3fcc717",
            "a8716362f3d54900ae044927e766aa43",
            "4e8022507a20450b9db9b11d253d232e",
            "afb71342a6264a4796c2500a9f36f049",
            "f330453f9cce4ca9b4968b0ce2984e1f",
            "6b712b87cf37437c91de18c98f5049f2",
            "f8f184bced824e55a70785d434f85db6",
            "4b2a4d3a3c44459398c4e34344bcd2cf",
            "70baa1357c384966add10623c10cd843",
            "295414888416408ea6a3785ae1498130",
            "ad8e0e5f575848798d7fc63dde766165",
            "79665ee45c764a7ea93f82213ac16bf2",
            "a9ce48a2e1fa48bba29d5285b1277254",
            "20f47cf323434649ba07566d0a9b5f06",
            "106b09c359bc4d26b59f5e03846c1884"
          ]
        },
        "id": "GmiNjtPd5I7b",
        "outputId": "8ee7f7ee-5ed1-4f61-a973-449b0c59ecf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1045 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d3d2b84f4f2473cb84a9d65b1c8ad2b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/55 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f330453f9cce4ca9b4968b0ce2984e1f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1045, 55)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nr0BGBR56JRN",
        "outputId": "597ca49c-dbdd-49b3-c681-a5e9476fd5e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.47.0)\n",
            "Requirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.8.0+cu126)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, torch\n",
        "from transformers import AutoModelForCausalLM, TrainingArguments, Trainer, BitsAndBytesConfig\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "class DynamicPaddingCausalCollator:\n",
        "    def __init__(self, tokenizer, pad_to_multiple_of=8):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.pad_to_multiple_of = pad_to_multiple_of\n",
        "    def __call__(self, features):\n",
        "        batch = self.tokenizer.pad(features, padding=True, return_tensors=\"pt\",\n",
        "                                   pad_to_multiple_of=self.pad_to_multiple_of)\n",
        "        labels = batch[\"input_ids\"].clone()\n",
        "        labels[batch[\"attention_mask\"] == 0] = -100\n",
        "        batch[\"labels\"] = labels\n",
        "        return batch\n",
        "\n",
        "collator = DynamicPaddingCausalCollator(tok)\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        ")\n",
        "\n",
        "print(\"Loading Phi-3 base model in 4-bit...\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    BASE_MODEL,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map={\"\": 0},\n",
        "    low_cpu_mem_usage=True,\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "\n",
        "model = prepare_model_for_kbit_training(model, use_gradient_checkpointing=True)\n",
        "\n",
        "lora_cfg = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\"gate_proj\",\"up_proj\",\"down_proj\"],\n",
        ")\n",
        "model = get_peft_model(model, lora_cfg)\n",
        "\n",
        "if hasattr(model, \"enable_input_require_grads\"):\n",
        "    model.enable_input_require_grads()\n",
        "model.gradient_checkpointing_enable(gradient_checkpointing_kwargs={\"use_reentrant\": False})\n",
        "model.config.use_cache = False\n",
        "\n",
        "try:\n",
        "    model.print_trainable_parameters()\n",
        "except:\n",
        "    print(\"Trainable tensors:\", sum(p.requires_grad for p in model.parameters()))\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=OUT_DIR,\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=8,\n",
        "    learning_rate=2e-4,\n",
        "    num_train_epochs=1,\n",
        "    logging_steps=25,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=250,\n",
        "    save_steps=250,\n",
        "    save_total_limit=2,\n",
        "    fp16=True,\n",
        "    bf16=False,\n",
        "    optim=\"paged_adamw_8bit\",\n",
        "    gradient_checkpointing=True,\n",
        "    group_by_length=True,\n",
        "    dataloader_num_workers=2,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_tok,\n",
        "    eval_dataset=val_tok,\n",
        "    data_collator=collator,\n",
        ")\n",
        "\n",
        "print(\"Starting training...\")\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683,
          "referenced_widgets": [
            "033ee0bf7c1f454bb0f496491bc51799",
            "b8d9acf3ff4748498cd4c2ca62dc481c",
            "d8d3b87700464d25abb31b4c24f9611c",
            "dd685c6f7a844f269194e7571ed304c4",
            "69bd9329486049d9bc87ec9ce0fad6ab",
            "61535f7737444153b24e771bc8da3100",
            "f7565bae7cdb48e4aa339bc757c8b9e3",
            "6a6b3e97464a4810841be9a8cbd8e3eb",
            "7a37c3ee079d41a6ae6b2900ae5f172f",
            "cffb8a3c421a4fe2ba71e16389e317d5",
            "7f7bce0f6f00408ab74b39ad6072a1eb"
          ]
        },
        "id": "wakqNsbF5aLb",
        "outputId": "92b3009d-178c-4473-f4ff-2a8adb4cefe3",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Phi-3 base model in 4-bit...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.0a67737cc96d2554230f90338b163bc6380a2a85.modeling_phi3:`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
            "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.0a67737cc96d2554230f90338b163bc6380a2a85.modeling_phi3:Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "033ee0bf7c1f454bb0f496491bc51799"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 8,912,896 || all params: 3,829,992,448 || trainable%: 0.2327\n",
            "Starting training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.0a67737cc96d2554230f90338b163bc6380a2a85.modeling_phi3:You are not running the flash-attention implementation, expect numerical differences.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='131' max='131' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [131/131 42:58, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=131, training_loss=0.11210915787529399, metrics={'train_runtime': 2599.4137, 'train_samples_per_second': 0.402, 'train_steps_per_second': 0.05, 'total_flos': 2.39579687288832e+16, 'train_loss': 0.11210915787529399, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- IMPORTS ---\n",
        "from transformers import AutoTokenizer, pipeline, BitsAndBytesConfig\n",
        "from peft import AutoPeftModelForCausalLM\n",
        "import re, json, torch, os, itertools\n",
        "import pulp\n",
        "\n",
        "# -----------------------------\n",
        "# CONFIG\n",
        "# -----------------------------\n",
        "LORA_DIR    = \"/content/drive/MyDrive/nl2lp_project/nl2lp-phi3-qlora/checkpoint-131\"  # <-- keep this\n",
        "OFFLOAD_DIR = \"/content/offload\"   # temp dir for CPU/Disk offload (must exist or be creatable)\n",
        "\n",
        "# Quantization toggles\n",
        "USE_8BIT = True\n",
        "USE_4BIT = False   # set True if you prefer 4-bit (requires bitsandbytes >= 0.41)\n",
        "\n",
        "os.makedirs(OFFLOAD_DIR, exist_ok=True)\n",
        "\n",
        "# -----------------------------\n",
        "# LOAD MODEL + TOKENIZER\n",
        "# (merges LoRA automatically)\n",
        "# -----------------------------\n",
        "tokenizer = AutoTokenizer.from_pretrained(LORA_DIR, use_fast=True)\n",
        "\n",
        "# Ensure pad/eos tokens are set to avoid generation warnings\n",
        "if tokenizer.pad_token is None and tokenizer.eos_token is not None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# --- Model kwargs ---\n",
        "model_kwargs = {\n",
        "    \"device_map\": \"auto\",           # GPU/CPU placement\n",
        "    \"torch_dtype\": \"auto\",\n",
        "    \"offload_folder\": OFFLOAD_DIR   # <-- correct arg name\n",
        "}\n",
        "\n",
        "# --- Quantization config ---\n",
        "bnb_config = None\n",
        "if USE_4BIT:\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16\n",
        "    )\n",
        "elif USE_8BIT:\n",
        "    bnb_config = BitsAndBytesConfig(load_in_8bit=True)\n",
        "\n",
        "if bnb_config:\n",
        "    model_kwargs[\"quantization_config\"] = bnb_config\n",
        "\n",
        "# --- Load model ---\n",
        "model = AutoPeftModelForCausalLM.from_pretrained(\n",
        "    LORA_DIR,\n",
        "    **model_kwargs\n",
        ").eval()\n",
        "\n",
        "# --- Pipeline ---\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# DETECT PROBLEM TYPE\n",
        "# -----------------------------\n",
        "def detect_problem_type(txt: str) -> str:\n",
        "    t = txt.lower()\n",
        "    if any(k in t for k in [\"tsp\", \"travelling salesman\", \"traveling salesman\", \"cities\"]):\n",
        "        return \"TSP\"\n",
        "    if any(k in t for k in [\"lp\", \"linear program\", \"linear optimization\", \"linear programming\"]):\n",
        "        return \"LP\"\n",
        "    if any(k in t for k in [\"constraint\", \"objective\", \"maximize\", \"minimize\"]) and \"route\" not in t:\n",
        "        return \"LP\"\n",
        "    return \"Unknown\"\n",
        "\n",
        "# -----------------------------\n",
        "# SYSTEM INSTRUCTIONS\n",
        "# -----------------------------\n",
        "SYSTEM_INSTRUCTIONS = \"\"\"\n",
        "You are a solver assistant.\n",
        "When the user gives a problem:\n",
        "\n",
        "- If it is a TSP problem:\n",
        "  → Extract all cities and costs.\n",
        "  → Expand into a symmetric cost matrix with 0 on diagonal.\n",
        "  → Always return ONLY one valid JSON in the format:\n",
        "\n",
        "{\n",
        "  \"problem_type\":\"TSP\",\n",
        "  \"known\":{\n",
        "    \"cities\":[...],\n",
        "    \"base_cost\":[[...]],\n",
        "    \"weights\":{\"cost\":1.0}\n",
        "  }\n",
        "}\n",
        "\n",
        "- If it is a Linear Programming problem:\n",
        "  → Identify objective (min/max), variables count from coefficients length, and constraints.\n",
        "  → Return ONLY one valid JSON in the format:\n",
        "\n",
        "{\n",
        "  \"problem_type\":\"LP\",\n",
        "  \"known\":{\n",
        "    \"objective\":\"min\" or \"max\",\n",
        "    \"objective_coeffs\":[...],\n",
        "    \"constraints\":[\n",
        "      {\"coeffs\":[...], \"sign\":\"<=\", \"rhs\":...}\n",
        "    ]\n",
        "  }\n",
        "}\n",
        "\n",
        "⚠️ RULES:\n",
        "- Output MUST contain only ONE JSON object.\n",
        "- Do NOT output \"Answer:\", \"NA\", \"MODE\", \"PROBLEM_TYPE\", or anything outside JSON.\n",
        "- Never explain, never add LaTeX, never add multiple formats.\n",
        "- If something is missing, assume defaults and still produce valid JSON.\n",
        "\"\"\"\n",
        "\n",
        "# -----------------------------\n",
        "# LLM CALL\n",
        "# -----------------------------\n",
        "def llm(prompt, max_new_tokens=700):\n",
        "    out = pipe(\n",
        "        prompt,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        do_sample=False,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        pad_token_id=tokenizer.pad_token_id or tokenizer.eos_token_id\n",
        "    )[0][\"generated_text\"]\n",
        "\n",
        "    # Remove prompt echo\n",
        "    if out.startswith(prompt):\n",
        "        out = out[len(prompt):].strip()\n",
        "\n",
        "    return out.strip()\n",
        "\n",
        "# -----------------------------\n",
        "# JSON EXTRACTION (balanced braces)\n",
        "# -----------------------------\n",
        "def extract_first_json_block(text: str):\n",
        "    \"\"\"\n",
        "    Robustly extract the first balanced JSON object from text.\n",
        "    Handles extra chatter before/after; ignores additional JSONs.\n",
        "    \"\"\"\n",
        "    start = text.find(\"{\")\n",
        "    if start == -1:\n",
        "        return None\n",
        "    depth = 0\n",
        "    in_str = False\n",
        "    esc = False\n",
        "    for i, ch in enumerate(text[start:], start=start):\n",
        "        if in_str:\n",
        "            if esc:\n",
        "                esc = False\n",
        "            elif ch == \"\\\\\":\n",
        "                esc = True\n",
        "            elif ch == '\"':\n",
        "                in_str = False\n",
        "        else:\n",
        "            if ch == '\"':\n",
        "                in_str = True\n",
        "            elif ch == \"{\":\n",
        "                depth += 1\n",
        "            elif ch == \"}\":\n",
        "                depth -= 1\n",
        "                if depth == 0:\n",
        "                    return text[start:i+1]\n",
        "    return None\n",
        "\n",
        "# -----------------------------\n",
        "# LP SOLVER (matches chatbot JSON schema)\n",
        "# -----------------------------\n",
        "def solve_lp_from_json(lp_json: dict):\n",
        "    known = lp_json[\"known\"]\n",
        "\n",
        "    # Sense\n",
        "    sense = pulp.LpMaximize if str(known.get(\"objective\", \"min\")).lower().startswith(\"max\") else pulp.LpMinimize\n",
        "    prob = pulp.LpProblem(\"Chatbot_LP\", sense)\n",
        "\n",
        "    # Variables: x1..xn (non-negative by default)\n",
        "    coeffs = known.get(\"objective_coeffs\", [])\n",
        "    if not isinstance(coeffs, list) or len(coeffs) == 0:\n",
        "        raise ValueError(\"objective_coeffs must be a non-empty list\")\n",
        "\n",
        "    n = len(coeffs)\n",
        "    variables = [f\"x{i+1}\" for i in range(n)]\n",
        "    vars_dict = {v: pulp.LpVariable(v, lowBound=0) for v in variables}\n",
        "\n",
        "    # Objective\n",
        "    prob += pulp.lpSum(c * vars_dict[v] for c, v in zip(coeffs, variables))\n",
        "\n",
        "    # Constraints\n",
        "    constraints = known.get(\"constraints\", [])\n",
        "    constraints_str = []\n",
        "    for idx, c in enumerate(constraints, 1):\n",
        "        c_coeffs = c.get(\"coeffs\", [])\n",
        "        if len(c_coeffs) != n:\n",
        "            raise ValueError(f\"Constraint {idx} coeffs length {len(c_coeffs)} != number of variables {n}\")\n",
        "        lhs = pulp.lpSum(a * vars_dict[v] for a, v in zip(c_coeffs, variables))\n",
        "        sign = c.get(\"sign\", \"<=\")\n",
        "        rhs = c.get(\"rhs\", 0)\n",
        "\n",
        "        if sign == \"<=\":\n",
        "            prob += lhs <= rhs\n",
        "        elif sign == \">=\":\n",
        "            prob += lhs >= rhs\n",
        "        elif sign == \"=\":\n",
        "            prob += lhs == rhs\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported constraint sign: {sign}\")\n",
        "\n",
        "        lhs_str = \" + \".join([f\"{a}*{v}\" for a, v in zip(c_coeffs, variables) if a != 0])\n",
        "        constraints_str.append(f\"{lhs_str} {sign} {rhs}\")\n",
        "\n",
        "    # Solve\n",
        "    prob.solve(pulp.PULP_CBC_CMD(msg=False))\n",
        "\n",
        "    status = pulp.LpStatus[prob.status]\n",
        "    obj_val = pulp.value(prob.objective)\n",
        "    var_vals = {v: pulp.value(var) for v, var in vars_dict.items()}\n",
        "\n",
        "    # Human-readable\n",
        "    obj_str = \" + \".join([f\"{c}*{v}\" for c, v in zip(coeffs, variables) if c != 0])\n",
        "    human = (\n",
        "        f\"Objective: {('max' if sense == pulp.LpMaximize else 'min')}imize Z = {obj_str}\\n\"\n",
        "        f\"Subject to:\\n\" + \"\\n\".join([f\"  {s}\" for s in constraints_str]) + \"\\n\\n\"\n",
        "        f\"Optimal Solution:\\n\"\n",
        "        f\"  Status: {status}\\n\"\n",
        "        f\"  Objective Value (Z): {obj_val}\\n\"\n",
        "        f\"  Variables: {var_vals}\\n\"\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"status\": status,\n",
        "        \"objective\": obj_val,\n",
        "        \"variables\": var_vals,\n",
        "        \"human_readable\": human\n",
        "    }\n",
        "\n",
        "# -----------------------------\n",
        "# TSP SOLVER\n",
        "# -----------------------------\n",
        "def tsp_nearest_neighbor(base_cost, start=0):\n",
        "    n = len(base_cost)\n",
        "    unvisited = set(range(n))\n",
        "    tour = [start]\n",
        "    unvisited.remove(start)\n",
        "    current = start\n",
        "    while unvisited:\n",
        "        nxt = min(unvisited, key=lambda j: base_cost[current][j])\n",
        "        tour.append(nxt)\n",
        "        unvisited.remove(nxt)\n",
        "        current = nxt\n",
        "    tour.append(start)\n",
        "    cost = sum(base_cost[tour[i]][tour[i+1]] for i in range(len(tour)-1))\n",
        "    return tour, cost\n",
        "\n",
        "def tsp_two_opt(base_cost, tour):\n",
        "    \"\"\"Simple 2-opt improvement.\"\"\"\n",
        "    n = len(tour) - 1  # last is start\n",
        "    improved = True\n",
        "    best = tour[:]\n",
        "    best_cost = sum(base_cost[best[i]][best[i+1]] for i in range(len(best)-1))\n",
        "    while improved:\n",
        "        improved = False\n",
        "        for i in range(1, n-1):\n",
        "            for k in range(i+1, n):\n",
        "                new_tour = best[:i] + best[i:k+1][::-1] + best[k+1:]\n",
        "                new_cost = sum(base_cost[new_tour[t]][new_tour[t+1]] for t in range(len(new_tour)-1))\n",
        "                if new_cost < best_cost:\n",
        "                    best, best_cost = new_tour, new_cost\n",
        "                    improved = True\n",
        "                    break\n",
        "            if improved:\n",
        "                break\n",
        "    return best, best_cost\n",
        "\n",
        "def hybrid_solve_tsp(known):\n",
        "    base_cost = known[\"base_cost\"]\n",
        "    cities = known.get(\"cities\")  # optional; if missing use indices A/B/C...\n",
        "    n = len(base_cost)\n",
        "\n",
        "    # If small (<=10), brute force exact; else NN + 2-opt heuristic\n",
        "    if n <= 10:\n",
        "        best_cost = float(\"inf\")\n",
        "        best_path = None\n",
        "        cities_idx = list(range(n))\n",
        "        for perm in itertools.permutations(cities_idx[1:]):  # fix start=0\n",
        "            path = [0] + list(perm) + [0]\n",
        "            cost = sum(base_cost[path[i]][path[i+1]] for i in range(len(path)-1))\n",
        "            if cost < best_cost:\n",
        "                best_cost = cost\n",
        "                best_path = path\n",
        "        route_idx = best_path\n",
        "        total_cost = best_cost\n",
        "        method = \"Exact (brute force)\"\n",
        "    else:\n",
        "        nn_route, nn_cost = tsp_nearest_neighbor(base_cost, start=0)\n",
        "        two_opt_route, two_opt_cost = tsp_two_opt(base_cost, nn_route)\n",
        "        route_idx = two_opt_route\n",
        "        total_cost = two_opt_cost\n",
        "        method = \"Heuristic (Nearest Neighbor + 2-opt)\"\n",
        "\n",
        "    # Labels\n",
        "    if cities and len(cities) == n:\n",
        "        route_labels = [cities[i] for i in route_idx]\n",
        "    else:\n",
        "        alpha_labels = [chr(ord('A') + i) for i in range(n)]\n",
        "        route_labels = [alpha_labels[i] for i in route_idx]\n",
        "\n",
        "    human = f\"Shortest Route ({method}): \" + \" → \".join(route_labels) + f\"\\nTotal Cost: {total_cost}\"\n",
        "\n",
        "    return {\n",
        "        \"status\": \"Optimal\" if n <= 10 else \"Feasible\",\n",
        "        \"best_cost\": total_cost,\n",
        "        \"route_indices\": route_idx,\n",
        "        \"route_labels\": route_labels,\n",
        "        \"human_readable\": human,\n",
        "        \"method\": method\n",
        "    }\n",
        "\n",
        "# -----------------------------\n",
        "# MASTER SOLVER (LP or TSP)\n",
        "# -----------------------------\n",
        "def solve_problem(parsed_json: dict):\n",
        "    ptype = parsed_json.get(\"problem_type\", \"\").upper()\n",
        "    if ptype == \"LP\":\n",
        "        return solve_lp_from_json(parsed_json)\n",
        "    elif ptype == \"TSP\":\n",
        "        return hybrid_solve_tsp(parsed_json[\"known\"])\n",
        "    else:\n",
        "        return {\"status\": \"Error\", \"human_readable\": \"❌ Unsupported problem type\", \"raw\": parsed_json}\n",
        "\n",
        "# -----------------------------\n",
        "# MAIN CHATBOT (ONE-SHOT)\n",
        "# -----------------------------\n",
        "def or_chatbot():\n",
        "    print(\"🤖 OR Chatbot (LP/TSP). Type 'exit' to quit.\")\n",
        "    user = input(\"\\nYou: \").strip()\n",
        "\n",
        "    if user.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
        "        print(\"Bot: Goodbye!\")\n",
        "        return\n",
        "\n",
        "    problem_type = detect_problem_type(user)\n",
        "    if problem_type == \"Unknown\":\n",
        "        print(\"Bot: ❌ Could not detect problem type (LP/TSP). Please rephrase.\")\n",
        "        return\n",
        "\n",
        "    # Build final prompt\n",
        "    prompt = f\"{SYSTEM_INSTRUCTIONS}\\n\\nUser Problem:\\n{user}\\n\\nJSON:\"\n",
        "    response = llm(prompt, max_new_tokens=700)\n",
        "\n",
        "    # Extract ONLY the first balanced JSON block\n",
        "    try:\n",
        "        response_json = extract_first_json_block(response)\n",
        "        if not response_json:\n",
        "            print(\"\\nBot: ❌ No JSON found in response\\n\", response)\n",
        "            return\n",
        "\n",
        "        parsed = json.loads(response_json)\n",
        "\n",
        "        # Show parsed JSON\n",
        "        print(\"\\nBot (Parsed JSON):\\n\", json.dumps(parsed, indent=2))\n",
        "\n",
        "        # Solve and show human-readable answer\n",
        "        result = solve_problem(parsed)\n",
        "        human = result.get(\"human_readable\")\n",
        "        if human:\n",
        "            print(\"\\nBot (Solution):\\n\" + human)\n",
        "        else:\n",
        "            print(\"\\nBot (Solution JSON):\\n\", json.dumps(result, indent=2))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"\\nBot: ❌ Error parsing/solving →\", e)\n",
        "        print(\"Raw LLM response:\\n\", response)\n",
        "\n",
        "    print(\"\\n✅ Conversation ended after one JSON response.\")\n",
        "\n",
        "# ---- RUN ----\n",
        "or_chatbot()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 744,
          "referenced_widgets": [
            "8625fb2bdda946a78e98fb10becb4d2d",
            "a8c7d270c9574510a4ffe66785ed5d80",
            "faea42d066e54ce3b20c999807cb611d",
            "e7f6fa782915452ab72d63dc0b42d26c",
            "56d16621268649bd904bfd017d68f0c3",
            "b32a681601b64077a245db56787e26b7",
            "53f93845442f4519b526a293157321a0",
            "9635256c50f146d982a902c22e8f3d6a",
            "650b690793154a8ba4833b2d665e4935",
            "a6d04f173bac4450b43ae7e321c9d040",
            "ef5999377214420f936f97ff1715bee9"
          ]
        },
        "id": "68xcSqMnf5Rx",
        "outputId": "fc05aa34-ae41-42ec-ed8f-a97cc4f11ce7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8625fb2bdda946a78e98fb10becb4d2d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🤖 OR Chatbot (LP/TSP). Type 'exit' to quit.\n",
            "\n",
            "You: A salesman must visit 5 cities: A, B, C, D, and E. The distances between the cities are: A-B=10, A-C=15, A-D=20, A-E=25, B-C=35, B-D=25, B-E=30, C-D=30, C-E=20, D-E=15. Find the shortest route that visits each city exactly once and returns to the starting city.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "/usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py:186: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bot: ❌ Error parsing JSON → Extra data: line 11 column 1 (char 236)\n",
            "{\n",
            "  \"problem_type\":\"TSP\",\n",
            "  \"known\":{\n",
            "    \"cities\":[\"A\", \"B\", \"C\", \"D\", \"E\"],\n",
            "    \"base_cost\":[[0, 10, 15, 20, 25], [10, 0, 35, 25, 30], [15, 35, 0, 30, 20], [20, 25, 30, 0, 15], [25, 30, 20, 15, 0]],\n",
            "    \"weights\":{\"cost\":1.0}\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "User Problem:\n",
            "A salesman must visit 5 cities: A, B, C, D, and E. The distances between the cities are: A-B=10, A-C=15, A are you able to solve this? Answer only with JSON: Cities: A, B, C, D, E. Distances: A-B=10, A-C=15, A-D=20, A-E=25, B-C=35, B-D=25, B-E=30, C-D=30, C-E=20, D-E=15. Formulate a TSP problem.\n",
            "\n",
            "JSON:\n",
            "{\n",
            "  \"problem_type\":\"TSP\",\n",
            "  \"known\":{\n",
            "    \"cities\":[\"A\", \"B\", \"C\", \"D\", \"E\"],\n",
            "    \"base_cost\":[[0, 10, 15, 20, 25], [10, 0, 35, 25, 30], [15, 35, 0, 30, 20], [20, 25, 30, 0, 15], [25, 30, 20, 15, 0]],\n",
            "    \"weights\":{\"cost\":1.0}\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "User Problem:\n",
            "A salesman must visit 5 cities: A, B, C, D, and E. The distances between the cities are: A-B=10, A-C=15, A-D=20, A-E=25, B-C=35, B-D=25, B-E=30, C-D=30, C-E=20, D-E=15. Formulate an LP problem. Minimize Z = 10x_A_B + 15x_A_C + 20x_A_D + 25x_A_E + 35x_B_C + 25x_B_D + 30x_B_E + 30x_C_D + 20x_C_E + 15x_D_E. Subject to x_A_B + x_A_C + x_A_D +\n",
            "\n",
            "✅ Conversation ended after one JSON response.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/astha1204/tspsolver.git\n"
      ],
      "metadata": {
        "id": "aetxEBUykIay",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bca38d5e-8786-4fb6-aaf4-1c44b56fa55b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'tspsolver'...\n",
            "remote: Enumerating objects: 8, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 8 (delta 0), reused 8 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (8/8), 5.32 KiB | 2.66 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd tspsolver\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcSwulhaGkUM",
        "outputId": "cbd0be46-1162-4fc2-9086-4ea1960f2060"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/tspsolver\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yu2mLNBuG8sG",
        "outputId": "68a77aaa-b485-40e1-acf2-2f423167051b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (0.116.1)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (2.11.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (2.0.2)\n",
            "Requirement already satisfied: pulp in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (3.2.2)\n",
            "Requirement already satisfied: ortools in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (9.14.6206)\n",
            "Requirement already satisfied: uvicorn[standard] in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (0.35.0)\n",
            "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi->-r requirements.txt (line 1)) (0.47.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from fastapi->-r requirements.txt (line 1)) (4.14.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]->-r requirements.txt (line 2)) (8.2.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]->-r requirements.txt (line 2)) (0.16.0)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]->-r requirements.txt (line 2)) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]->-r requirements.txt (line 2)) (1.1.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]->-r requirements.txt (line 2)) (6.0.2)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]->-r requirements.txt (line 2)) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]->-r requirements.txt (line 2)) (1.1.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]->-r requirements.txt (line 2)) (15.0.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->-r requirements.txt (line 3)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->-r requirements.txt (line 3)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->-r requirements.txt (line 3)) (0.4.1)\n",
            "Requirement already satisfied: absl-py>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ortools->-r requirements.txt (line 6)) (2.3.1)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ortools->-r requirements.txt (line 6)) (2.2.2)\n",
            "Requirement already satisfied: protobuf<6.32,>=6.31.1 in /usr/local/lib/python3.12/dist-packages (from ortools->-r requirements.txt (line 6)) (6.31.1)\n",
            "Requirement already satisfied: immutabledict>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from ortools->-r requirements.txt (line 6)) (4.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->ortools->-r requirements.txt (line 6)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->ortools->-r requirements.txt (line 6)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->ortools->-r requirements.txt (line 6)) (2025.2)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.48.0,>=0.40.0->fastapi->-r requirements.txt (line 1)) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi->-r requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->ortools->-r requirements.txt (line 6)) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mv1q46F1HBPz",
        "outputId": "9b5cdbc7-0f84-4352-8b20-631d671d7f09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r tspsolver/* .\n"
      ],
      "metadata": {
        "id": "cbWfMFJlIir1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZF0gXSTYIl-L",
        "outputId": "0737a9ca-0a51-4e4d-d7d2-f61c5768e6eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (0.116.1)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (2.11.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (2.0.2)\n",
            "Requirement already satisfied: pulp in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (3.2.2)\n",
            "Requirement already satisfied: ortools in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (9.14.6206)\n",
            "Requirement already satisfied: uvicorn[standard] in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (0.35.0)\n",
            "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi->-r requirements.txt (line 1)) (0.47.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from fastapi->-r requirements.txt (line 1)) (4.14.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]->-r requirements.txt (line 2)) (8.2.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]->-r requirements.txt (line 2)) (0.16.0)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]->-r requirements.txt (line 2)) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]->-r requirements.txt (line 2)) (1.1.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]->-r requirements.txt (line 2)) (6.0.2)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]->-r requirements.txt (line 2)) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]->-r requirements.txt (line 2)) (1.1.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]->-r requirements.txt (line 2)) (15.0.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->-r requirements.txt (line 3)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->-r requirements.txt (line 3)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->-r requirements.txt (line 3)) (0.4.1)\n",
            "Requirement already satisfied: absl-py>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ortools->-r requirements.txt (line 6)) (2.3.1)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ortools->-r requirements.txt (line 6)) (2.2.2)\n",
            "Requirement already satisfied: protobuf<6.32,>=6.31.1 in /usr/local/lib/python3.12/dist-packages (from ortools->-r requirements.txt (line 6)) (6.31.1)\n",
            "Requirement already satisfied: immutabledict>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from ortools->-r requirements.txt (line 6)) (4.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->ortools->-r requirements.txt (line 6)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->ortools->-r requirements.txt (line 6)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->ortools->-r requirements.txt (line 6)) (2025.2)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.48.0,>=0.40.0->fastapi->-r requirements.txt (line 1)) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi->-r requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->ortools->-r requirements.txt (line 6)) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import main\n",
        "import models\n",
        "import nlp_parser\n",
        "import solver\n"
      ],
      "metadata": {
        "id": "ILKSsw5bI1I2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example LP Test\n",
        "chatbot_output = {\n",
        "    \"problem_type\": \"LP\",\n",
        "    \"known\": {\n",
        "        \"objective\": \"Maximize profit\",\n",
        "        \"variables\": [\"T\", \"C\"],\n",
        "        \"constraints\": [\"4T + 3C <= 240\", \"T >= 0\", \"C >= 0\"],\n",
        "        \"objective_function\": \"50T + 30C\"\n",
        "    }\n",
        "}\n",
        "\n",
        "result = solve_problem(chatbot_output)\n",
        "print(result)\n",
        "\n"
      ],
      "metadata": {
        "id": "FySvGPqehBuS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acc47e9f-cbc6-4063-ae8a-e707b543be1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'status': 'Optimal', 'objective': 3000.0, 'variables': {'T': 60.0, 'C': 0.0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example TSP Test\n",
        "chatbot_output = {\n",
        "    \"problem_type\": \"TSP\",\n",
        "    \"known\": {\n",
        "        \"base_cost\": [\n",
        "            [0, 10, 15, 20],\n",
        "            [10, 0, 35, 25],\n",
        "            [15, 35, 0, 30],\n",
        "            [20, 25, 30, 0]\n",
        "        ],\n",
        "        \"weights\": {\"cost\": 1.0}\n",
        "    }\n",
        "}\n",
        "\n",
        "result = solve_problem(chatbot_output)\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "V2v9rcfJhEa3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5d8ad22-8da2-4335-e2b7-78be83ac5d4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'status': 'Optimal', 'route': [0, 1, 3, 2, 0], 'objective': 80.0}\n"
          ]
        }
      ]
    }
  ]
}